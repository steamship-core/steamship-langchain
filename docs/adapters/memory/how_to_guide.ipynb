{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How-To Guide: Memory\n",
    "\n",
    "This notebook shows how to use Steamship-backed memory to persist state in your LangChain applications.\n",
    "\n",
    "For demonstration purposes, we will use a temporary workspace. In production environments, a permanent workspace would be used to provide persistence, as well as user-scoping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain, PromptTemplate\n",
    "from steamship import Steamship\n",
    "from steamship_langchain.llms import OpenAI\n",
    "import logging\n",
    "\n",
    "logging.disable(logging.CRITICAL)  # disable warning messages to declutter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a prompt for use\n",
    "\n",
    "template = \"\"\"You are a chatbot having a conversation with a human.\n",
    "\n",
    "{history}\n",
    "Human: {human_input}\n",
    "Chatbot:\"\"\"\n",
    "\n",
    "chat_prompt = PromptTemplate(input_variables=[\"history\", \"human_input\"], template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a series of inputs for the converation (as an example)\n",
    "\n",
    "user_messages = [\n",
    "    \"Do you prefer glazed doughnuts or old-fashioned doughnuts?\",\n",
    "    \"How does that compare to chocolate eclairs in your opinion?\",\n",
    "    \"Would you prefer that or a croissant for breakfast?\",\n",
    "    \"What is the best place to get some near where you live?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Do you prefer glazed doughnuts or old-fashioned doughnuts?\n",
      "AI:  That's a tough one! I think I would have to go with glazed doughnuts. They just have a special something that old-fashioned doughnuts don't have.\n",
      "Human: How does that compare to chocolate eclairs in your opinion?\n",
      "AI:  I think chocolate eclairs are delicious, but they don't quite compare to the sweetness and texture of glazed doughnuts.\n",
      "Human: Would you prefer that or a croissant for breakfast?\n",
      "AI:  I think I would prefer a croissant for breakfast. Croissants are light and fluffy, and they pair well with a cup of coffee.\n",
      "Human: What is the best place to get some near where you live?\n",
      "AI:  The best place to get croissants near me is a local bakery called Sweet Tooth Bakery. They have the freshest and most delicious croissants around!\n",
      "\n",
      "\n",
      "--- Persistent Transcript From Memory ---\n",
      "Human: Do you prefer glazed doughnuts or old-fashioned doughnuts?\n",
      "AI:  That's a tough one! I think I would have to go with glazed doughnuts. They just have a special something that old-fashioned doughnuts don't have.\n",
      "Human: How does that compare to chocolate eclairs in your opinion?\n",
      "AI:  I think chocolate eclairs are delicious, but they don't quite compare to the sweetness and texture of glazed doughnuts.\n",
      "Human: Would you prefer that or a croissant for breakfast?\n",
      "AI:  I think I would prefer a croissant for breakfast. Croissants are light and fluffy, and they pair well with a cup of coffee.\n",
      "Human: What is the best place to get some near where you live?\n",
      "AI:  The best place to get croissants near me is a local bakery called Sweet Tooth Bakery. They have the freshest and most delicious croissants around!\n"
     ]
    }
   ],
   "source": [
    "# use persistent chat memory\n",
    "from steamship_langchain.memory import ChatMessageHistory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "with Steamship.temporary_workspace() as client:\n",
    "    saved_history = ChatMessageHistory(client=client, key=\"example-user-chat-1234\")\n",
    "    memory = ConversationBufferMemory(chat_memory=saved_history)\n",
    "\n",
    "    chatgpt = LLMChain(\n",
    "        llm=OpenAI(client=client, temperature=0),\n",
    "        prompt=chat_prompt,\n",
    "        memory=memory,\n",
    "    )\n",
    "\n",
    "    for message in user_messages:\n",
    "        print(f\"Human: {message}\")\n",
    "        print(f\"AI: {chatgpt.predict(human_input=message)}\")\n",
    "\n",
    "    print(\"\\n\\n--- Persistent Transcript From Memory ---\")\n",
    "\n",
    "    print(f\"{memory.load_memory_variables(inputs={}).get('history', '')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Do you prefer glazed doughnuts or old-fashioned doughnuts?\n",
      "AI:  That's a tough one! I think I would have to go with glazed doughnuts. They just have a special something that old-fashioned doughnuts don't have.\n",
      "Human: How does that compare to chocolate eclairs in your opinion?\n",
      "AI:  I think chocolate eclairs are delicious, but they don't quite compare to the sweetness and texture of glazed doughnuts.\n",
      "Human: Would you prefer that or a croissant for breakfast?\n",
      "AI:  I think I would prefer a croissant for breakfast. Croissants are light and fluffy, and they pair well with a cup of coffee.\n",
      "Human: What is the best place to get some near where you live?\n",
      "AI:  The best place to get croissants near me is a local bakery called Sweet Treats. They make the most delicious croissants in town!\n",
      "\n",
      "\n",
      "--- Persistent Transcript From Memory (k=2) ---\n",
      "Human: Would you prefer that or a croissant for breakfast?\n",
      "AI:  I think I would prefer a croissant for breakfast. Croissants are light and fluffy, and they pair well with a cup of coffee.\n",
      "Human: What is the best place to get some near where you live?\n",
      "AI:  The best place to get croissants near me is a local bakery called Sweet Treats. They make the most delicious croissants in town!\n"
     ]
    }
   ],
   "source": [
    "# use persistent chat memory\n",
    "from steamship_langchain.memory import ChatMessageHistory\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "with Steamship.temporary_workspace() as client:\n",
    "    saved_history = ChatMessageHistory(client=client, key=\"example-user-chat-1234\")\n",
    "    memory = ConversationBufferWindowMemory(chat_memory=saved_history, k=2)\n",
    "\n",
    "    chatgpt = LLMChain(\n",
    "        llm=OpenAI(client=client, temperature=0),\n",
    "        prompt=chat_prompt,\n",
    "        memory=memory,\n",
    "    )\n",
    "\n",
    "    for message in user_messages:\n",
    "        print(f\"Human: {message}\")\n",
    "        print(f\"AI: {chatgpt.predict(human_input=message)}\")\n",
    "\n",
    "    print(\"\\n\\n--- Persistent Transcript From Memory (k=2) ---\")\n",
    "\n",
    "    print(f\"{memory.load_memory_variables(inputs={}).get('history', '')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "834117f4e0f61aee809513abffa40d5ecdde34fc37831cd637d73e61f5d7de69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
